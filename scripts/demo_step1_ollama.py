"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  CIVICHACKS 2026 â€” LIVE DEMO STEP 1                        â•‘
â•‘  "The 60-Second AI"                                         â•‘
â•‘                                                              â•‘
â•‘  Proves: You can run a GPT-4-class model locally, for free  â•‘
â•‘  Time on stage: ~60 seconds                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Run this during the opening segment (0:00-0:05) right after
the DeepSeek R1 story. The audience sees a local model respond
in real time â€” no API key, no cloud, no cost.

PREREQUISITE: Ollama installed and model pulled
  $ ollama pull llama3.1
"""

import ollama
import platform
import sys
import time
from datetime import datetime

# â”€â”€ A civic-flavored prompt to make the demo relevant â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROMPT = """You are a civic technology advisor. In 3 concise bullet points,
explain why open source AI matters for building tools that serve
communities â€” especially for students at a hackathon who want to
make a real impact this weekend."""

def main():
    hostname = platform.node()
    now = datetime.now().strftime("%B %d, %Y at %I:%M:%S %p")

    print("\nğŸ›ï¸  CivicHacks 2026 â€” Open Source AI, Running Locally\n")
    print(f"ğŸ“¡ Model: llama3.1 (8B) â€” running on {hostname}")
    print(f"ğŸ• Time: {now}")
    print(f"ğŸ’° Cost: $0.00")
    print(f"ğŸ”’ Data: never leaves {hostname}\n")
    print("â”€" * 60)
    print(f"\nğŸ’¬ Prompt: {PROMPT.strip()}\n")
    print("â”€" * 60)
    print("\nğŸ¤– Response:\n")

    start = time.time()

    # Stream the response so the audience watches it generate
    stream = ollama.chat(
        model="llama3.1",
        messages=[{"role": "user", "content": PROMPT}],
        stream=True,
    )

    token_count = 0
    for chunk in stream:
        content = chunk["message"]["content"]
        print(content, end="", flush=True)
        token_count += len(content.split())

    elapsed = time.time() - start
    print(f"\n\nâ”€" + "â”€" * 59)
    print(f"â±ï¸  Generated in {elapsed:.1f}s  |  ~{token_count} words  |  Cost: $0.00")
    print(f"â”€" * 60)
    print(f"\nâœ… That's it. Local AI. Free. Private. Ready to build with.\n")

if __name__ == "__main__":
    main()
